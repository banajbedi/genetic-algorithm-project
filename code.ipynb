{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5afd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7730ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Banaj\\anaconda3\\envs\\ds_project1\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d532ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a5642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flength</th>\n",
       "      <th>Fwidth</th>\n",
       "      <th>Fsize</th>\n",
       "      <th>Fconc</th>\n",
       "      <th>Fconc1</th>\n",
       "      <th>Fasym</th>\n",
       "      <th>Fm3long</th>\n",
       "      <th>Fm3trans</th>\n",
       "      <th>Falpha</th>\n",
       "      <th>Fdist</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19020 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Flength    Fwidth   Fsize   Fconc  Fconc1     Fasym   Fm3long  \\\n",
       "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
       "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       Fm3trans   Falpha     Fdist Class  \n",
       "0       -8.2027  40.0920   81.8828     g  \n",
       "1       -9.9574   6.3609  205.2610     g  \n",
       "2      -45.2160  76.9600  256.7880     g  \n",
       "3       -7.1513  10.4490  116.7370     g  \n",
       "4       21.8393   4.6480  356.4620     g  \n",
       "...         ...      ...       ...   ...  \n",
       "19015    2.8766   2.4229  106.8258     h  \n",
       "19016   -2.9632  86.7975  247.4560     h  \n",
       "19017   -9.4662  30.2987  256.5166     h  \n",
       "19018  -63.8389  84.6874  408.3166     h  \n",
       "19019   31.4755  52.7310  272.3174     h  \n",
       "\n",
       "[19020 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35ff4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].map({'g':0, 'h':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0f7b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flength</th>\n",
       "      <th>Fwidth</th>\n",
       "      <th>Fsize</th>\n",
       "      <th>Fconc</th>\n",
       "      <th>Fconc1</th>\n",
       "      <th>Fasym</th>\n",
       "      <th>Fm3long</th>\n",
       "      <th>Fm3trans</th>\n",
       "      <th>Falpha</th>\n",
       "      <th>Fdist</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Flength    Fwidth   Fsize   Fconc  Fconc1     Fasym  Fm3long  Fm3trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    Falpha     Fdist  Class  \n",
       "0  40.0920   81.8828      0  \n",
       "1   6.3609  205.2610      0  \n",
       "2  76.9600  256.7880      0  \n",
       "3  10.4490  116.7370      0  \n",
       "4   4.6480  356.4620      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0dd75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flength     False\n",
       "Fwidth      False\n",
       "Fsize       False\n",
       "Fconc       False\n",
       "Fconc1      False\n",
       "Fasym       False\n",
       "Fm3long     False\n",
       "Fm3trans    False\n",
       "Falpha      False\n",
       "Fdist       False\n",
       "Class       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8323cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a54b3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a16ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TPOTClassifier(verbosity=2, population_size=15, max_eval_time_mins=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31fccb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/1515 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8073606729758149\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8073606729758149\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8085524009814231\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8085524009814231\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8462670872765511\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.8462670872765511\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.8462670872765511\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.8462670872765511\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.8462670872765511\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.8462670872765511\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.8472485103399929\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.8472485103399929\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.849421661409043\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.8520855240098142\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.8520855240098142\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.85285664213109\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.85285664213109\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.85285664213109\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 25 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 26 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 27 - Current best internal CV score: 0.8529267437784789\n",
      "\n",
      "Generation 28 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 29 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 30 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 31 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 32 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 33 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 34 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 35 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 36 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 37 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 38 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 39 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 40 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 41 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 42 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 43 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 44 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 45 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 46 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 47 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 48 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 49 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 50 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 51 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 52 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 53 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 54 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 55 - Current best internal CV score: 0.8534174553101999\n",
      "\n",
      "Generation 56 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 57 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 58 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 59 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 60 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 61 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 62 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 63 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 64 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 65 - Current best internal CV score: 0.8535576586049773\n",
      "\n",
      "Generation 66 - Current best internal CV score: 0.853627760252366\n",
      "\n",
      "Generation 67 - Current best internal CV score: 0.853627760252366\n",
      "\n",
      "Generation 68 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 69 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 70 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 71 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 72 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 73 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 74 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 75 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 76 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 77 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 78 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 79 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 80 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 81 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 82 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 83 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 84 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 85 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 86 - Current best internal CV score: 0.8536978618997546\n",
      "\n",
      "Generation 87 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 88 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 89 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 90 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 91 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 92 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 93 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 94 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 95 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 96 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 97 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 98 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 99 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Generation 100 - Current best internal CV score: 0.8552400981423063\n",
      "\n",
      "Best pipeline: DecisionTreeClassifier(SGDClassifier(LinearSVC(input_matrix, C=10.0, dual=False, loss=squared_hinge, penalty=l2, tol=0.001), alpha=0.001, eta0=0.01, fit_intercept=False, l1_ratio=1.0, learning_rate=constant, loss=log, penalty=elasticnet, power_t=100.0), criterion=gini, max_depth=9, min_samples_leaf=13, min_samples_split=20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(max_eval_time_mins=0.02, population_size=15, random_state=42,\n",
       "               verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(max_eval_time_mins=0.02, population_size=15, random_state=42,\n",
       "               verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(max_eval_time_mins=0.02, population_size=15, random_state=42,\n",
       "               verbosity=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d563e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Banaj\\anaconda3\\envs\\ds_project1\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:765: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Banaj\\anaconda3\\envs\\ds_project1\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8475289169295478"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa080032",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(\"best_pipeline.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354824c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
